import json
from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from dataclasses import dataclass
from langchain.tools import tool, ToolRuntime

# 1. å®šä¹‰å·¥å…·
@tool
def get_weather(city: str) -> str:
    """æŸ¥è¯¢å®æ—¶å¤©æ°”"""
    return f"{city} å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸© 25Â°C"

# 2. å®šä¹‰æ¨¡å‹ (æ”¯æŒé™æ€é…ç½®)
model = ChatOpenAI(model="Qwen3-235B-A22B", temperature=0, api_key="sk-dIl9oEE1SCJHXkzkdTmivPJgtxMGHNgvvNx5e17T4XYHBBOG", base_url="http://10.1.18.99:8089/v1")


# å®šä¹‰ä¸Šä¸‹æ–‡ç»“æ„
@dataclass
class UserContext:
    user_id: str
    is_vip: bool

@tool
def check_balance(runtime: ToolRuntime[UserContext]) -> str:
    """
    æŸ¥è¯¢ä½™é¢ã€‚
    æ³¨æ„ï¼šruntime å‚æ•°å¯¹ LLM éšèº«ï¼ŒLLM è®¤ä¸ºæ­¤å·¥å…·ä¸éœ€è¦å‚æ•°ï¼
    """
    # ç›´æ¥ä»è¿è¡Œæ—¶è·å–ä¸Šä¸‹æ–‡ï¼Œæ— éœ€æ¨¡å‹ä¼ å‚
    ctx = runtime.context
    
    # æ¨¡æ‹Ÿé€»è¾‘
    base_balance = 100
    if ctx.is_vip:
        return f"å°Šè´µçš„ VIP ç”¨æˆ· {ctx.user_id}ï¼Œæ‚¨çš„ä½™é¢æ˜¯ {base_balance * 10} å…ƒ"
    return f"ç”¨æˆ· {ctx.user_id}ï¼Œæ‚¨çš„ä½™é¢æ˜¯ {base_balance} å…ƒ"

# --- è°ƒç”¨ç¯èŠ‚ ---
# å‡è®¾è¿™æ˜¯ä» API ç½‘å…³è·å–çš„å½“å‰ç”¨æˆ·ä¿¡æ¯
current_user = UserContext(user_id="alice_888", is_vip=True)


# 3. åˆ›å»º Agent (åº•å±‚è‡ªåŠ¨æ„å»º Graph)
agent = create_agent(model, tools=[get_weather, check_balance])

# 4. è¿è¡Œ
result = agent.invoke(
    {"messages": [{"role": "user", "content": "æˆ‘è¿˜æœ‰å¤šå°‘é’±ï¼Ÿ"}]},
    context=current_user  # <--- å…³é”®æ³¨å…¥ç‚¹
)
print(result["messages"][-1].content)


from pydantic import BaseModel, Field
from langchain.agents.structured_output import ToolStrategy

# å®šä¹‰æœŸæœ›çš„æ•°æ®ç»“æ„
class SentimentReport(BaseModel):
    score: int = Field(description="æƒ…æ„Ÿè¯„åˆ† 1-10")
    tags: list[str] = Field(description="æƒ…æ„Ÿå…³é”®è¯ï¼Œå¦‚ï¼šæ„¤æ€’ã€å¼€å¿ƒ")

agent = create_agent(
    model=model,
    tools=[], 
    # æ ¸å¿ƒï¼šç»‘å®šç»“æ„ + å¼€å¯é”™è¯¯å¤„ç†
    response_format=ToolStrategy(
        schema=SentimentReport,
        handle_errors=True  # <--- å¼€å¯è‡ªåŠ¨çº é”™
    )
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "è¿™ä¸ªäº§å“å¤ªçƒ‚äº†ï¼Œç‰©æµæ…¢å¾—è¦æ­»ï¼"}]
})

# ç›´æ¥è·å–å¼ºç±»å‹å¯¹è±¡
report = result["structured_response"]
print(f"è¯„åˆ†: {report.score}, æ ‡ç­¾: {report.tags}")
# è¾“å‡º: è¯„åˆ†: 2, æ ‡ç­¾: ['æ„¤æ€’', 'å¤±æœ›']


from langgraph.checkpoint.memory import InMemorySaver 
# ç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨: from langgraph.checkpoint.postgres import PostgresSaver

checkpointer = InMemorySaver()

agent = create_agent(
    model=model,
    tools=[get_weather, check_balance],
    checkpointer=checkpointer # æŒ‚è½½å­˜æ¡£å™¨
)

# ç¬¬ä¸€æ¬¡å¯¹è¯ï¼ŒæŒ‡å®š thread_id
config = {"configurable": {"thread_id": "session_1"}}
result = agent.invoke({"messages": [{"role": "user", "content": "æˆ‘å«äº‘æ¢"}]}, config)
print(result["messages"][-1].content)

# ç¬¬äºŒæ¬¡å¯¹è¯ï¼Œå®ƒä¾ç„¶è®°å¾—ä½ 
result = agent.invoke({"messages": [{"role": "user", "content": "æˆ‘å«ä»€ä¹ˆï¼Ÿ"}]}, config)
print(result["messages"][-1].content)
# AI: "ä½ å« äº‘æ¢"

from langchain.agents.middleware import dynamic_prompt, ModelRequest

@dynamic_prompt
def dynamic_system_message(request: ModelRequest) -> str:# ä» context ä¸­è·å–ç”¨æˆ·ç­‰çº§
    level = request.runtime.context.get("level", "junior")
    
    base_prompt = "ä½ æ˜¯ä¸€ä¸ª Python ä¸“å®¶ã€‚" 
    if level == "senior":
        return base_prompt + "è¯·ç›´æ¥ç»™å‡ºæç®€çš„é«˜çº§ä»£ç ï¼Œä¸è¦åºŸè¯ã€‚"
    return base_prompt + "è¯·åƒè€å¸ˆä¸€æ ·è¯¦ç»†è§£é‡Šæ¯ä¸€è¡Œä»£ç ã€‚"# æŒ‚è½½ä¸­é—´ä»¶

agent = create_agent(
    model=model, 
    middleware=[dynamic_system_message],
)

result = agent.invoke({"messages": [{"role": "user", "content": "è¯·å†™ä¸€ä¸ªæ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‡½æ•°"}]}, context={"level": "senior"})
print(result["messages"][-1].content)

from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from langchain_core.messages import HumanMessage

@tool
def get_weather(city: str) -> str:
    """æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯"""
    return f"{city} ä»Šæ—¥å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸© 25Â°Cï¼Œé€‚åˆå‡ºæ¸¸ã€‚"

@tool
def calculator(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼"""
    return str(eval(expression))

agent = create_agent(model, tools=[get_weather, calculator])

input_msg = {
    "messages": [
        HumanMessage(content="å¸®æˆ‘æŸ¥ä¸€ä¸‹åŒ—äº¬çš„å¤©æ°”ï¼Œç„¶åæ ¹æ®æ°”æ¸©è®¡ç®—ä¸€ä¸‹ï¼šå¦‚æœæ¯åº¦æ°”æ¸©éœ€è¦å– 10ml æ°´ï¼Œæˆ‘ä»Šå¤©éœ€è¦å–å¤šå°‘æ°´ï¼Ÿ")
    ]
}

print(f"--- ğŸš€ å¼€å§‹å¤„ç†è¯·æ±‚: {input_msg['messages'][0].content} ---")

# stream_mode="updates" æ„å‘³ç€æ¯å½“ Graph ä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹å®Œæˆå·¥ä½œï¼Œå°±æ¨é€ä¸€æ¬¡æ›´æ–°
for chunk in agent.stream(input_msg, stream_mode="updates"):
    for node, update in chunk.items():
        
        # -------------------------------------------------
        # åœºæ™¯ A: æ•è· Agent èŠ‚ç‚¹çš„åŠ¨ä½œ (æ¨¡å‹æ€è€ƒ & å†³å®š)
        # -------------------------------------------------
        if node == "model":
            if "messages" in update:
                ai_msg = update["messages"][-1]
                
                # 1. æ¨¡å‹å†³å®šè°ƒç”¨å·¥å…·
                if ai_msg.tool_calls:
                    for tool_call in ai_msg.tool_calls:
                        print(f"\nğŸ¤– [Agent æ€è€ƒ] å†³å®šè°ƒç”¨å·¥å…·: {tool_call['name']}")
                        print(f"    â””â”€ å‚æ•°: {tool_call['args']}")
                
                # 2. æ¨¡å‹ç›´æ¥å›å¤ (æˆ–æ€è€ƒè¿‡ç¨‹)
                elif ai_msg.content:
                    # æ³¨æ„ï¼šæœ‰äº›æ¨¡å‹åœ¨è°ƒç”¨å·¥å…·å‰ä¹Ÿä¼šè¾“å‡ºä¸€æ®µ content æ–‡æœ¬
                    print(f"\nğŸ’¬ [Agent å›å¤]: {ai_msg.content}")

        # -------------------------------------------------
        # åœºæ™¯ B: æ•è· Tools èŠ‚ç‚¹çš„åŠ¨ä½œ (å·¥å…·å®é™…æ‰§è¡Œç»“æœ)
        # -------------------------------------------------
        elif node == "tools":
            if "messages" in update:
                tool_msg = update["messages"][-1]
                
                print(f"\nğŸ› ï¸ [Tools æ‰§è¡Œ] å·¥å…·è¿è¡Œå®Œæ¯•")
                # tool_msg.content å°±æ˜¯å·¥å…·å‡½æ•°çš„ return å€¼
                print(f"    â””â”€ ç»“æœ: {tool_msg.content}")

print("\n--- âœ… æµç¨‹ç»“æŸ ---")

from langchain.agents import create_agent
from langchain_openai import ChatOpenAI
from langchain.tools import tool
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import Command, interrupt

from langgraph.errors import GraphInterrupt

@tool
def request_refund(amount: int) -> str:
    """å‘èµ·é€€æ¬¾ç”³è¯·ã€‚"""
    print(f"\n[Tool] 1. æ”¶åˆ°é€€æ¬¾è¯·æ±‚: {amount}å…ƒ")
    print("[Tool] 2. æ­£åœ¨è¯·æ±‚äººå·¥å®¡æ ¸ï¼Œç¨‹åºå°†åœ¨æ­¤æš‚åœ...")

    approval_result = interrupt(f"ç”³è¯·é€€æ¬¾ {amount} å…ƒï¼Œè¯·ç®¡ç†å‘˜æ‰¹ç¤º")

    # --- æ¢å¤æ‰§è¡Œåï¼Œä»è¿™é‡Œç»§ç»­è·‘ ---
    print(f"[Tool] 3. æ”¶åˆ°å®¡æ ¸ç»“æœ: {approval_result}")

    if approval_result == "å®¡æ ¸é€šè¿‡":
        # é€»è¾‘æ²¡æœ‰æ–­ï¼æˆ‘ä»¬å¯ä»¥ç»§ç»­è°ƒç”¨å…¶ä»–å‡½æ•°
        result = execute_refund_transaction(amount)
        return f"å®¡æ ¸é€šè¿‡ï¼Œ{result}"
    else:
        return f"å®¡æ ¸æ‹’ç»ã€‚åŸå› : {approval_result}"

def execute_refund_transaction(amount: int) -> str:
    """æ¨¡æ‹Ÿé“¶è¡Œè½¬è´¦é€»è¾‘"""
    print(f"\nâš¡ [Bank API] æ­£åœ¨æ‰§è¡Œè½¬è´¦: {amount}å…ƒ...")
    return f"è½¬è´¦æˆåŠŸï¼š{amount}å…ƒå·²é€€å›ç”¨æˆ·è´¦æˆ·ã€‚"


# åˆå§‹åŒ–å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒé€šå¸¸ä½¿ç”¨ PostgresSaverï¼‰
# å¦‚æœæ²¡æœ‰ checkpointerï¼Œä¸­æ–­åçŠ¶æ€å°±ä¼šä¸¢å¤±ï¼Œæ— æ³• resume
checkpointer = InMemorySaver()

agent = create_agent(
    model, 
    tools=[request_refund], 
    checkpointer=checkpointer
)

thread_config = {"configurable": {"thread_id": "tx_123"}}

print("--- é˜¶æ®µ 1: ç”¨æˆ·å‘èµ·è¯·æ±‚ ---")

try:
    # Agent ä¼šæ€è€ƒ -> è°ƒç”¨ request_refund -> è§¦å‘ Interrupt -> æŠ›å‡º GraphInterrupt å¼‚å¸¸
    agent.invoke(
        {"messages": [{"role": "user", "content": "æˆ‘è¦é€€æ¬¾ 100 å…ƒ"}]}, 
        thread_config
    )
except GraphInterrupt as e:
    # æ•è·ä¸­æ–­å¼‚å¸¸
    print(f"â¸ï¸  ä»»åŠ¡å·²æš‚åœ! æ”¶åˆ°ä¸­æ–­ä¿¡å·: {e}")
    print("    (å½“å‰çŠ¶æ€å·²ä¿å­˜åˆ°å†…å­˜ä¸­)")


print("\n--- é˜¶æ®µ 2: äººå·¥å®¡æ ¸ ---")
# è¿™é‡Œæ¨¡æ‹Ÿç®¡ç†å‘˜åœ¨æ§åˆ¶å°è¾“å…¥ï¼Œå®é™…åœºæ™¯å¯èƒ½æ˜¯å‰ç«¯çš„ä¸€ä¸ªæŒ‰é’®
user_approval = input("ç®¡ç†å‘˜ï¼šæ‰¹å‡†é€€æ¬¾å—ï¼Ÿ(è¾“å…¥ y æ‰¹å‡†ï¼Œå…¶ä»–æ‹’ç»): ")

# å†³å®šæ¢å¤æ‰§è¡Œæ—¶çš„è¿”å›å€¼
if user_approval.lower() == "y":
    resume_value = "å®¡æ ¸é€šè¿‡"
    print("    -> ç®¡ç†å‘˜å·²æ‰¹å‡†ã€‚")
else:
    resume_value = "å®¡æ ¸æ‹’ç»ï¼šé‡‘é¢è¿‡å¤§"
    print("    -> ç®¡ç†å‘˜å·²æ‹’ç»ã€‚")

print("\n--- ğŸ”„ é˜¶æ®µ 3: æ¢å¤æ‰§è¡Œ ---")

# ä½¿ç”¨ Command(resume=...) æ¢å¤æ‰§è¡Œ
# è¿™é‡Œçš„ resume_value ä¼šç›´æ¥ä½œä¸º request_refund å·¥å…·çš„â€œè¿”å›å€¼â€ç»™åˆ° LLM
# æ­¤æ—¶ LLM çœ‹åˆ°çš„å†å²æ˜¯ï¼š
# User: é€€æ¬¾ 100 -> AI: è°ƒç”¨ request_refund -> Tool Output: "å®¡æ ¸é€šè¿‡" (æˆ‘ä»¬æ³¨å…¥çš„å€¼)
result = agent.invoke(
    Command(resume=resume_value), 
    thread_config
)


print("\n--- âœ… æœ€ç»ˆç»“æœ ---")
# æ‰“å°æœ€åä¸€æ¡æ¶ˆæ¯å†…å®¹
last_message = result["messages"][-1]
print(f"AI å›å¤: {last_message.content}")

from typing import List, Annotated
from typing_extensions import TypedDict

from langchain.agents import create_agent, AgentState
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langchain_core.messages import ToolMessage
from langchain_core.tools.base import InjectedToolCallId
from langgraph.prebuilt import InjectedState
from langgraph.types import Command
from langgraph.checkpoint.memory import InMemorySaver

# 1. å®šä¹‰çŠ¶æ€ Schema

class AnalystState(AgentState):
    scratchpad: List[str]  # æ‰©å±•å­—æ®µï¼šè‰ç¨¿æœ¬

# 2. å®šä¹‰å·¥å…·ï¼šå†™ & è¯»

@tool
def batch_save_notes(
    notes: List[str], 
    # ä½¿ç”¨æ ‡å‡†æ³¨å…¥æ–¹å¼è·å– ID å’Œ çŠ¶æ€
    tool_call_id: Annotated[str, InjectedToolCallId], 
    state: Annotated[AnalystState, InjectedState]
) -> Command:
    """
    ã€æ‰¹é‡å†™å…¥å·¥å…·ã€‘å°†å¤šä¸ªå…³é”®å‘ç°ä¸€æ¬¡æ€§è®°å½•åˆ°è‰ç¨¿æœ¬ã€‚
    å‚æ•° notes: ä¸€ä¸ªå­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¾‹å¦‚ ["é¡¹ç›®Aé¢„ç®—å¢åŠ ", "é¡¹ç›®Bå–æ¶ˆ"]
    """
    # 1. è·å–å½“å‰è‰ç¨¿æœ¬
    current_pad = state.get("scratchpad", [])
    
    # 2. æ‰¹é‡è¿½åŠ 
    new_pad = current_pad + notes
    
    print(f"ğŸ“ [Notepad] æ­£åœ¨æ‰¹é‡è®°å½• {len(notes)} æ¡æ•°æ®...")
    for n in notes:
        print(f"   - {n}")

    # 3. æ›´æ–°çŠ¶æ€
    return Command(
        update={
            "scratchpad": new_pad,
            "messages": [
                ToolMessage(
                    content=f"æˆåŠŸæ‰¹é‡è®°å½•äº† {len(notes)} æ¡ç¬”è®°ã€‚",
                    tool_call_id=tool_call_id
                )
            ]
        }
    )

@tool
def read_notes(
    # è¯»å–ä¹Ÿéœ€è¦è·å– State
    state: Annotated[AnalystState, InjectedState]
) -> str:
    """
    ã€è¯»å–å·¥å…·ã€‘è¯»å–è‰ç¨¿æœ¬ä¸­çš„æ‰€æœ‰å†…å®¹ã€‚
    """
    current_pad = state.get("scratchpad", [])
    
    if not current_pad:
        return "è‰ç¨¿æœ¬æ˜¯ç©ºçš„ã€‚"
    
    print("ğŸ“– [Notepad] Agent æ­£åœ¨å›é¡¾ç¬”è®°...")
    
    formatted_notes = "\n".join([f"{i+1}. {note}" for i, note in enumerate(current_pad)])
    return f"--- è‰ç¨¿æœ¬å†…å®¹ ---\n{formatted_notes}\n----------------"

system_prompt = """
ä½ æ˜¯ä¸€åä»ä¸é—æ¼ç»†èŠ‚çš„æ•°æ®å½•å…¥å‘˜ã€‚
ä½ çš„ä»»åŠ¡æ˜¯æå–ç”¨æˆ·è¾“å…¥ä¸­çš„**æ‰€æœ‰äº‹å®æ•°æ®**å¹¶å­˜å…¥è‰ç¨¿æœ¬ã€‚

ã€æ‰§è¡Œè§„åˆ™ã€‘
1. åˆ†æè¾“å…¥ï¼Œå°†å…¶æ‹†è§£ä¸ºç‹¬ç«‹çš„â€œäº‹å®ç‚¹â€ã€‚
2. **å¿…é¡»**è°ƒç”¨ `batch_save_notes` å·¥å…·ï¼Œå°†è¿™äº›äº‹å®ç‚¹ä½œä¸ºä¸€ä¸ª**åˆ—è¡¨**ä¸€æ¬¡æ€§å­˜å…¥ã€‚
3. å¦‚æœè¾“å…¥åŒ…å«å¤šä¸ªé¡¹ç›®ï¼ˆå¦‚é¡¹ç›®Aã€Bã€Cï¼‰ï¼Œä½ çš„åˆ—è¡¨é‡Œå¿…é¡»åŒ…å«å¯¹åº”çš„å¤šæ¡æ•°æ®ã€‚

ã€âŒ ä¸¥ç¦äº‹é¡¹ã€‘
1. ä¸¥ç¦è®°å½•â€œç”¨æˆ·è®©æˆ‘åˆ†æ...â€æˆ–â€œå¤„ç†å¤æ‚ä¿¡æ¯...â€è¿™ç±»æŒ‡ä»¤ã€‚åªè®°å½•**ä¸šåŠ¡æ•°æ®**ã€‚
2. ä¸¥ç¦å‡­ç©ºæé€ æ•°æ®ã€‚
"""

checkpointer = InMemorySaver()

agent = create_agent(
    model,
    tools=[batch_save_notes, read_notes],    
    state_schema=AnalystState,
    system_prompt=system_prompt,
    checkpointer=checkpointer
)

config = {"configurable": {"thread_id": "analysis_session_1"}}

# åˆå§‹åŒ–çŠ¶æ€
initial_state = {
    "messages": [],
    "scratchpad": [] # åˆå§‹åŒ–ä¸ºç©º
}


# æ¨¡æ‹Ÿç¬¬ä¸€æ­¥ï¼šè®© Agent åˆ†æä¸€æ®µå¤æ‚çš„æ–‡æœ¬å¹¶è®°å½•
# è¿™é‡Œçš„ invoke ä¼šè§¦å‘ Agent æ€è€ƒ -> è°ƒç”¨ save_note -> æ›´æ–° State
user_input_1 = """
è¯·åˆ†æä»¥ä¸‹ä¼šè®®è®°å½•å¹¶è®°å½•å…³é”®ç‚¹ï¼š
é¡¹ç›®Açš„é¢„ç®—ä»50ä¸‡å¢åŠ åˆ°äº†80ä¸‡ï¼Œæˆªæ­¢æ—¥æœŸæ¨è¿Ÿåˆ°äº†12æœˆ31æ—¥ã€‚
é¡¹ç›®Bå·²è¢«å–æ¶ˆï¼Œèµ„æºè½¬ç§»åˆ°äº†é¡¹ç›®Cã€‚
é¡¹ç›®Cç°åœ¨çš„è´Ÿè´£äººå˜æˆäº†Aliceï¼Œé¢„ç®—ä¸º20ä¸‡ã€‚
"""

agent.invoke(
    {"messages": [{"role": "user", "content": user_input_1}], **initial_state},
    config
)

# æ¨¡æ‹Ÿç¬¬äºŒæ­¥ï¼šè¿½åŠ ä¿¡æ¯
# æ³¨æ„ï¼šæˆ‘ä»¬ä¸éœ€è¦æŠŠä¸Šä¸€è½®çš„ user_input_1 å†ä¼ ä¸€éï¼ŒState å·²ç»åœ¨ Graph é‡Œäº†
print("\n--- ğŸ”„ è¿½åŠ ä¿¡æ¯ ---")
user_input_2 = "è¡¥å……ä¸€ç‚¹ï¼šé¡¹ç›®Açš„è´Ÿè´£äººè¿˜æ˜¯Bobï¼Œä½†ä»–ä¸‹ä¸ªæœˆè¦ç¦»èŒã€‚"
agent.invoke(
    {"messages": [{"role": "user", "content": user_input_2}]},
    config
)

# æ¨¡æ‹Ÿç¬¬ä¸‰æ­¥ï¼šæœ€ç»ˆæ±‡æ€»
# Agent åº”è¯¥ä¼šå…ˆè°ƒç”¨ read_notesï¼Œç„¶åå†å›ç­”
print("\n--- ğŸ“Š è¯·æ±‚æ±‡æ€» ---")
final_response = agent.invoke(
    {"messages": [{"role": "user", "content": "å¥½äº†ï¼Œç°åœ¨æ ¹æ®ä½ è‰ç¨¿æœ¬é‡Œçš„å†…å®¹ï¼Œç»™æˆ‘ç”Ÿæˆä¸€ä»½æœ€ç»ˆçš„é¡¹ç›®çŠ¶æ€æŠ¥å‘Šã€‚"}]},
    config
)

print("\n--- âœ… æœ€ç»ˆæŠ¥å‘Š ---")
print(final_response["messages"][-1].content)

# éªŒè¯ï¼šæˆ‘ä»¬å¯ä»¥ç›´æ¥ä» State ä¸­æŸ¥çœ‹è‰ç¨¿æœ¬ï¼Œçœ‹çœ‹å®ƒå­˜äº†ä»€ä¹ˆ
print("\n--- ğŸ•µï¸â€â™‚ï¸ (åå°æ•°æ®æ£€æŸ¥) è‰ç¨¿æœ¬å†…å®¹ ---")
final_state = agent.get_state(config)
print(json.dumps(final_state.values.get("scratchpad"), indent=2, ensure_ascii=False))


# [
#   "é¡¹ç›®Aé¢„ç®—å¢åŠ ",
#   "é¡¹ç›®Bå–æ¶ˆ",
#   "é¡¹ç›®Cå»¶æœŸè‡³ä¸‹å­£åº¦",
#   "é¡¹ç›®Aè´Ÿè´£äººæ˜¯Bob",
#   "Bobä¸‹ä¸ªæœˆå°†ç¦»èŒ"
# ]